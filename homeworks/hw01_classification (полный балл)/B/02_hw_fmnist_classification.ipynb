{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pXvjH9BFpERc"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rtu6146cpERd"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTne3ThApERe"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArmGcbkbpERf",
        "outputId": "25b15856-78d4-4fc1-daec-a621f26b8736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 17:54:04--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-09 17:54:04--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-09 17:54:05 (167 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Y0_ovkcpERf"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uDftPQ0ypERl"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "aYcL28OsgSq8",
        "outputId": "4be704ae-b760-4a6a-b009-1b1a214a9eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 113MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.86MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 57.3MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 3')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Принимает изображение размером (1, 28, 28) (1 канал, 28x28 пикселей).\n",
        "        # Применяет 32 фильтра (ядра) размером 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        # Max-Pooling: уменьшает размеры в 2 раза (28x28 → 14x14)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Принимает 32 карты признаков (результат первого сверточного слоя) и применяет 64 фильтра.\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Преобразует 3D-тензор (64 карты × 7x7 пикселей (потому что 28 - 14 - 7, два пуллинга было)) в одномерный вектор из 128 нейронов\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # 128 входов → 10 выходов (классы FashionMNIST)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_task_1 = SimpleCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265351cf-48de-4dc8-ba63-49b2f534d378"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "ba88d775-f274-4f68-ad4c-038db4ca21e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56796bf-6e3f-4607-fe83-aa218cc77a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5434998609542847\n",
            "Epoch 2/10, Loss: 0.3662589709877968\n",
            "Epoch 3/10, Loss: 0.31284266841014224\n",
            "Epoch 4/10, Loss: 0.28152719699939094\n",
            "Epoch 5/10, Loss: 0.2556437518497308\n",
            "Epoch 6/10, Loss: 0.23691428559621175\n",
            "Epoch 7/10, Loss: 0.22445605304141839\n",
            "Epoch 8/10, Loss: 0.20943689932872853\n",
            "Epoch 9/10, Loss: 0.1963891197020809\n",
            "Epoch 10/10, Loss: 0.18598677919829884\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model_task_1.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_task_1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_data_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f6f87f-4642-4765-baa4-90034ea1a54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.95473\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2ff70e-bf8a-44d4-ea6c-869ef54c4ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9197\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wIeB1YVpER2"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygdH1Iv0pER2",
        "outputId": "bd4606ae-ebe4-474e-8734-dcf1fb2bc29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxKGH4jTpER2"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}